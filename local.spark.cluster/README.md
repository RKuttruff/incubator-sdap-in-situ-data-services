- ref: https://www.kdnuggets.com/2020/07/apache-spark-cluster-docker.html

docker-compose up



- JupyterLab at localhost:8888;
- Spark master at localhost:8080;
- Spark worker I at localhost:8081;
- Spark worker II at localhost:8082;


### S3 connection
- https://stackoverflow.com/questions/30385981/how-to-access-s3a-files-from-apache-spark
- https://sparkour.urizone.net/recipes/using-s3/
- https://medium.com/@bogdan.cojocar/how-to-read-parquet-data-from-s3-using-the-s3a-protocol-and-temporary-credentials-in-pyspark-f94071bf8c6a